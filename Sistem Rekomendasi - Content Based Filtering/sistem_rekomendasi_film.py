# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Film.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1liYiCRSGFjksu9T8wJhuNUxpLkzjQclm

# Load Data

Pada tahap pertama, kita akan memuat data yang disimpah di google drive.
"""

#Memuat file dari google drive
from google.colab import drive
drive.mount('/content/drive')
base_dir='/content/drive/MyDrive/Colab_Notebooks/data-train/'

"""# Data Understanding

Pada tahap ini, kita akan melakukan pemahaman tentang data yang akan kita pakai sebelum membuat sistem komendasi untuk film berdasarkan sinopsis.
"""

#Membaca file csv dengan library Pandas
import pandas as pd
df = pd.read_csv(base_dir+'/movies_metadata.csv')
df

"""Kita memiliki 24 attribute data dimana masing-masing memiliki 45466 sample. Sekarang kita akan melihat tipe data tiap attribute."""

#Fungsi info() untuk melihat tipe data
df.info()

"""Perhatikan bahwa kita sebagian besar memiliki tipe data bertipe object, kecuali revenue, runtime, vote_average, dan vote_count. Sekarang kita akan melihat seberapa banyak data yang unik untuk memeriksa apakah data memiliki duplikat atau missing value."""

#Memeriksa data untuk attribute tittle
print('Banyak data: ', len(df.title.unique()))
print('Judul Film ', df.title.unique())

#Memeriksa data untuk attribute overview
print('Banyak data: ', len(df.overview.unique()))
print('Judul Film ', df.overview.unique())

"""Perhatikan bahwa kita memiliki jumlah data yang berbeda tiap attribute, yang artinya data kita memiliki missing value yang harus kita olah terlebih dahulu.

# Data Preparation

Pada tahap ini, kita akan mengolah dan memilah data pada attribute yang akan dipakai. Karena kita akan membuat sistem rekomendasi berdasarkan sinopsis maka kita hanya perlu dua attribute yang akan dipakai, yaitu tittle dan overview. Teknik yang akan dipakai juga tidak banya karena attribute yang dipakai hanya dua dan memiliki tipe data object.

Pertama kita akan membuang attribute yang tidak dibutuhkan dalam pembuatan sistem rekomendasi ini.
"""

#Mmebuang attribute yang tidak dipakai
df.drop(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language', 'original_title', 
                'release_date', 'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'video', 'vote_average', 'vote_count', 
         'popularity', 'poster_path', 'production_companies', 'production_countries'], axis=1, inplace=True)

df.head()

"""Kemudian, kita akan memeriksa jumlah missing value pada masing-masing attribute."""

#Banyak missing value tiap attribute
df.isnull().sum()

"""Perhatikan bahwa terdapat missing value sebanyak 954 untuk overview dan tittle sebanyak 6. Kita bisa melakukan dropping mengingat jumlah data yang kita pakai adalah puluhan ribu dan missing value yang sedikit. Alasan lain untuk melakukan dropping adalah sample tiap attribute adalah unik sehingga kita tidak bisa mengolahnya dengan pendekatan statistik seperti modus.

Karena ditemukan missing value yang sedikit maka kita bisa lakukan pembuangan sampel yang mengandung missing value.
"""

#Membuang sampel yang memuat missing value
df1 = df.dropna()

#Memeriksa apakah masih ada missing value
df1.isnull().sum()

"""Perhatikan bahwa missing value pada masing-masing attribute sudah tidak ada. Oleh karena itu, kita bisa melakukan tahapan selanjutnya, yaitu Modelling & Result

# Modelling & Result

Pada tahap ini kita akan membuat sistem rekomendasi berdasarkan sinopsis dimana kita akan membuat kelas untuk sistem tersebut yang berisikan tiga fungsi, yaitu __init__() , fit(), dan rekomendasi().

__init__() : fungsi inisialisasi untuk memasukkan nilai awal, seperti data dan konten kolom yang akan digunakan 

fit() : fungsi untuk encoding kolom yang memuliki sampel bertipe object.

rekomendasi() : fungsi untuk melakukan ranking dengan menggunakan metriks cosine disantce.
"""

from sklearn.feature_extraction.text import CountVectorizer
from nltk.tokenize import word_tokenize
from sklearn.metrics.pairwise import cosine_distances

#Pembuatan sistem rekomendasi berdasarkan sinopsis
#pembuatan class yang berisikan 3 fungsi
class SistemRekomendasi : 
  #fungsi inisialisasi
  def __init__(self, data, konten_kol):
    self.df = data
    self.konten_kol = konten_kol
    self.encoder = None
    self.bank = None
  
  #fungsi untuk encoding sample pada kolom overview
  def fit(self):
    self.encoder = CountVectorizer(stop_words = 'english', tokenizer = word_tokenize)
    self.bank = self.encoder.fit_transform(self.df[self.konten_kol])

  #Fungsi untuk melakukan rekomendasi berdasarkan metriks cosine distance
  def rekomendasi(self, idx, top_n=10):
    konten = df.loc[idx, self.konten_kol]
    kode = self.encoder.transform([konten])
    jarak = cosine_distances(kode, self.bank)
    rek_idx = jarak.argsort()[0, 1:(top_n + 1)]
    return self.df.loc[rek_idx]

import nltk
nltk.download('punkt')

#Mencoba sistem rekomendasi
#untuk merekomendasikan film
#yang sam dengan jumanji
rekom = SistemRekomendasi(df1, konten_kol = 'overview')
rekom.fit()
rekom.rekomendasi(1) #index 1 : Jumanji

"""Hasil diatas merupakan hasil dari top-10 rekomendasi film berdasarkan sinopsis dari film Jumanji. Selanjutnya kita akan melakukan evaluasi apakah dengan rekomendasi berdasarkan sinopsis sistem dikatakan baik atau tidak.

#Evaluaiton

Pada tahap ini kita melakukan evaluasi terhadap sistem rekomendasi sudah dipakai. Tahapannya sama dengan kita membuat sistem sebelumnya. Pertama, kita akan melakukan transformasi terhadap attribute overview dengan fungsi CountVectorizer
"""

#Transformasi data dengan CountVectorizer untuk seluruh sample pada kolom overview
bow = CountVectorizer(stop_words = "english", tokenizer = word_tokenize)
bank = bow.fit_transform(df1.overview)

#Memeriksa dan membuat variabel content untuk dilakukan evaluasi
idx = 2 # Film Grumpier Old Man
cont = df.loc[idx, "overview"]
cont

#Tranformasi data untuk sinopsis pada film Grumpier Old Man
code = bow.transform([cont])
code

"""Hasil encoding sebelumnya akan dijadikan evaluasi dengan menggunakan cosine distance untuk melihat jarak antar vektor tiap film berdasarkan sudut yang dibentuk. Disini kita bisa melihat sudut yang dibentuk antar vektor film Grumpier Old Man dengan film yang lainnya."""

#Penghitungan jarak berdasarkan sudut yang dibentuk antar film
jarak = cosine_distances(code, bank)
jarak

#Pengurutan berdasrkan nilai cosine distance
rekom = jarak.argsort()[0, 1:11]
rekom

#Melihat hasil dalam bentuk Dataframe
df.loc[rekom]

"""Selanjutnya, kita akan mengevaluasi sistem rekomendasi yang sudah kita buat dengan menggunakan nDCG score. nDCG adalah rasio skor DCG peserta atas skor DCG peringkat ideal. Score yang diperoleh dari nDCG berada diantara 0 dan 1. Semakin besar nilai socrenya maka sistem kita berhasil melakukan ranking terhadap suatu item.

Pada tahap ini kita akan mambuat array yang berisi top-10 rekomendasi dari film yang sudah kita rujuk sebagai nilai prediksi dan array yang berisi top 10 rekomendasi berdasarkan penalaran kita atau ranking dari google sebagai nilai aktual.
"""

import numpy as np
#Prediksi 
pred = [[cosine_distances(code, bank[13277])[0][0],
         cosine_distances(code, bank[36267])[0][0],
         cosine_distances(code, bank[8004])[0][0],
         cosine_distances(code, bank[24983])[0][0],
         cosine_distances(code, bank[30928])[0][0],
         cosine_distances(code, bank[9090])[0][0],
         cosine_distances(code, bank[4526])[0][0],
         cosine_distances(code, bank[20813])[0][0],
         cosine_distances(code, bank[10769])[0][0],
         cosine_distances(code, bank[12245])[0][0],
         ]]

np.asarray(pred)

#Aktual
aktual = [[cosine_distances(code, bank[334])[0][0], #While You Were Sleeping
          cosine_distances(code, bank[5483])[0][0], #Sweet Home Alabama
          cosine_distances(code, bank[907])[0][0], #Father of the Bride
          cosine_distances(code, bank[2579])[0][0], #Big Daddy
          cosine_distances(code, bank[4492])[0][0], #Look Who's Talking
          cosine_distances(code, bank[248])[0][0], # I.Q.
          cosine_distances(code, bank[328])[0][0], #Tommy Boy
          cosine_distances(code, bank[677])[0][0], #Mrs. Winterbourne
          cosine_distances(code, bank[2609])[0][0], #Runaway Bride
          cosine_distances(code, bank[6028])[0][0], # Dennis the Menace
          ]]

np.asarray(aktual)

"""Kita akan menghitubg score nDCG dengan menggunakan library sklearn.metrics dengan fungsi ndcg_score."""

#Melihat seberapa baik sistem kira untuk ranking dengan metriks nDCG
from sklearn.metrics import ndcg_score
ndcg_score(np.asarray(aktual), np.asarray(pred))

"""Perhatikan bahwa nilai yang dihasilkan mendekati satu, artinya sistem rekomendasi yang kita buat melakukan ranking dengan baik berdasarkan nilai yang dikembalikan oleh fungsi similarity yang kita deklarasikan. Namun, Meskipun hasil yang diberikan baik berdasarkan score yang didapat, hasil realita tidak sesuai yang diinginkan. Misal, While You Were Sleeping adalah film romantis yang mana sama dengan film yang kita rujul tetapi sistem tidak merekomendasikan hal tersebut karena sistem merekomendasikan berdasarkan sinopsis saja."""